{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0d9fe3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据库连接成功\n"
     ]
    }
   ],
   "source": [
    "##%%\n",
    "# Cell 1: 导入库和全局配置\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 全局配置\n",
    "class Config:\n",
    "    DB_URL = 'mysql+mysqlconnector://root:@localhost:3306/pokemon?charset=utf8mb4'  # 添加字符集\n",
    "    STATS = [\"hp\", \"attack\", \"defense\", \"sp_attack\", \"sp_defense\", \"speed\"]\n",
    "    TYPE_LIST = [\"bug\", \"dark\", \"dragon\", \"electric\", \"fairy\", \"fight\", \"fire\", \"flying\",\n",
    "                \"ghost\", \"grass\", \"ground\", \"ice\", \"normal\", \"poison\", \"psychic\",\n",
    "                \"rock\", \"steel\", \"water\"]  # 保持与数据集列名一致\n",
    "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    SEED = 42\n",
    "    NUM_RANDOM_TEAMS = 200_000\n",
    "    BATCH_SIZE = 256\n",
    "    NUM_EPOCHS = 15\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, df: pd.DataFrame):\n",
    "        \"\"\"数据校验\"\"\"\n",
    "        # 校验主键唯一性\n",
    "        assert df['pokedex_number'].is_unique, \"主键pokedex_number不唯一\"\n",
    "        \n",
    "        # 校验类型字段长度\n",
    "        type_columns = ['type1', 'type2']\n",
    "        for col in type_columns:\n",
    "            max_len = df[col].str.len().max()\n",
    "            assert max_len <= 20, f\"列 {col} 存在超过20字符的值（最大长度：{max_len}）\"\n",
    "            \n",
    "        # 校验对抗属性列存在\n",
    "        required_columns = [f'against_{t}' for t in cls.TYPE_LIST]\n",
    "        missing = set(required_columns) - set(df.columns)\n",
    "        assert not missing, f\"缺失对抗属性列：{missing}\"\n",
    "\n",
    "# 初始化数据库连接（添加连接测试）\n",
    "try:\n",
    "    engine = create_engine(Config.DB_URL)\n",
    "    with engine.connect() as test_conn:\n",
    "        test_conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"数据库连接成功\")\n",
    "except Exception as e:\n",
    "    print(f\"数据库连接失败: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# 种子设置\n",
    "random.seed(Config.SEED)\n",
    "np.random.seed(Config.SEED)\n",
    "torch.manual_seed(Config.SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(Config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "82c18970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_dtypes(df):\n",
    "    # 验证类型特征\n",
    "    type_cols = [f\"type{i}_{t}\" for i in (1,2) for t in Config.TYPE_LIST]\n",
    "    for col in type_cols:\n",
    "        assert df[col].dtype == np.int8, f\"{col} 类型错误：{df[col].dtype}\"\n",
    "        \n",
    "    # 验证能力向量\n",
    "    assert all(isinstance(x, np.ndarray) for x in df.abilities_vec), \"能力向量类型错误\"\n",
    "    \n",
    "    # 验证数值列\n",
    "    numeric_cols = [\"height_m\", \"weight_kg\", \"base_egg_steps\",\n",
    "                   \"capture_rate\", \"experience_growth\", \"base_happiness\", \n",
    "                   \"generation\", \"is_legendary\"] + Config.STATS\n",
    "    for col in numeric_cols:\n",
    "        assert pd.api.types.is_numeric_dtype(df[col]), f\"{col} 不是数值类型\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "589ba2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseLoader:\n",
    "    def __init__(self):\n",
    "        self.engine = create_engine(Config.DB_URL)\n",
    "        self.df = None\n",
    "        self.top_abil = None\n",
    "\n",
    "    def _execute_query(self, query):\n",
    "        with self.engine.connect() as conn:\n",
    "            return conn.execute(text(query))\n",
    "\n",
    "    def load_data(self):\n",
    "        query = \"SELECT * FROM pokemon\"\n",
    "        self.df = pd.read_sql(query, self.engine)\n",
    "        self._preprocess_data()\n",
    "        return self.df, self.top_abil\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        # 基础数据清洗\n",
    "        self.df[\"type2\"] = self.df[\"type2\"].fillna(\"None\")\n",
    "        \n",
    "        # 处理技能列表\n",
    "        self._process_abilities()\n",
    "        \n",
    "        # 类型特征处理\n",
    "        self._process_types()\n",
    "        \n",
    "        # 数值列处理\n",
    "        self._process_numeric()\n",
    "        \n",
    "        # 最终验证\n",
    "        self._final_validation()\n",
    "\n",
    "    def _process_abilities(self):\n",
    "        \"\"\"处理技能相关特征\"\"\"\n",
    "        # 解析原始技能数据\n",
    "        self.df[\"abilities\"] = self.df[\"abilities\"].apply(\n",
    "            lambda s: json.loads(s.replace(\"'\", '\"')) if isinstance(s, str) else []\n",
    "        )\n",
    "        \n",
    "        # 构建top50技能向量\n",
    "        all_abil = [a for lst in self.df.abilities for a in lst]\n",
    "        self.top_abil = pd.Series(all_abil).value_counts().nlargest(50).index.tolist()\n",
    "        \n",
    "        # 转换为float32 numpy数组\n",
    "        self.df[\"abilities_vec\"] = self.df[\"abilities\"].apply(\n",
    "            lambda lst: np.array(\n",
    "                [1.0 if ab in lst else 0.0 for ab in self.top_abil],\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _process_types(self):\n",
    "        \"\"\"处理类型相关特征\"\"\"\n",
    "        # 生成类型特征列\n",
    "        type_dummies = pd.get_dummies(\n",
    "            self.df[[\"type1\", \"type2\"]],\n",
    "            prefix=[\"type1\", \"type2\"],\n",
    "            columns=[\"type1\", \"type2\"],\n",
    "            dtype=np.int8\n",
    "        )\n",
    "        \n",
    "        # 确保包含所有可能类型\n",
    "        for t in Config.TYPE_LIST:\n",
    "            for prefix in [\"type1\", \"type2\"]:\n",
    "                col = f\"{prefix}_{t}\"\n",
    "                if col not in type_dummies:\n",
    "                    type_dummies[col] = 0\n",
    "                    \n",
    "        self.df = pd.concat([self.df, type_dummies], axis=1)\n",
    "\n",
    "    def _process_numeric(self):\n",
    "        \"\"\"处理数值特征\"\"\"\n",
    "        numeric_cols = [\n",
    "            \"height_m\", \"weight_kg\", \"base_egg_steps\",\n",
    "            \"capture_rate\", \"experience_growth\", \"base_happiness\",\n",
    "            \"generation\", \"is_legendary\"\n",
    "        ] + Config.STATS\n",
    "        \n",
    "        # 强制转换为float32\n",
    "        self.df[numeric_cols] = self.df[numeric_cols].apply(\n",
    "            pd.to_numeric, errors='coerce', downcast='float'\n",
    "        ).fillna(0).astype(np.float32)\n",
    "        \n",
    "        # 标准化统计值\n",
    "        stats_mean = self.df[Config.STATS].mean()\n",
    "        stats_std = self.df[Config.STATS].std()\n",
    "        self.df[Config.STATS] = (self.df[Config.STATS] - stats_mean) / stats_std\n",
    "\n",
    "    def _final_validation(self):\n",
    "        \"\"\"最终数据验证\"\"\"\n",
    "        # 验证技能向量\n",
    "        assert all(isinstance(x, np.ndarray) for x in self.df.abilities_vec), \"技能向量必须为numpy数组\"\n",
    "        assert all(x.dtype == np.float32 for x in self.df.abilities_vec), \"技能向量必须为float32\"\n",
    "        \n",
    "        # 验证类型特征\n",
    "        type_cols = [f\"type1_{t}\" for t in Config.TYPE_LIST] + [f\"type2_{t}\" for t in Config.TYPE_LIST]\n",
    "        assert all(self.df[col].dtype == np.int8 for col in type_cols), \"类型特征必须为int8\"\n",
    "        \n",
    "        # 验证数值列\n",
    "        numeric_cols = Config.STATS + [\"generation\", \"is_legendary\"]\n",
    "        assert all(pd.api.types.is_float_dtype(self.df[col]) for col in numeric_cols), \"数值列必须为float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "412da1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# Cell 3: TypeEffectiveness类定义\n",
    "class TypeEffectiveness:\n",
    "    def __init__(self):\n",
    "        self.matrix = self._build_matrix()\n",
    "    \n",
    "    def _build_matrix(self):\n",
    "        eff = np.ones((18, 18))\n",
    "        eff[0, 9] = 2.0   # Bug vs Grass\n",
    "        eff[0, 14] = 2.0  # Bug vs Psychic\n",
    "        eff[0, 1] = 2.0   # Bug vs Dark\n",
    "        return torch.tensor(eff, dtype=torch.float32)\n",
    "    \n",
    "    def get_multiplier(self, attack_type, defend_type):\n",
    "        a_idx = Config.TYPE_LIST.index(attack_type)\n",
    "        d_idx = Config.TYPE_LIST.index(defend_type)\n",
    "        return self.matrix[a_idx, d_idx].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1d12e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# Cell 4: BattleSimulator类定义\n",
    "class BattleSimulator:\n",
    "    def __init__(self, type_matrix):\n",
    "        self.type_matrix = type_matrix\n",
    "    \n",
    "    def duel_prob(self, p_row, q_row):\n",
    "        is_phys = random.random() < 0.5\n",
    "        a_stat = \"attack\" if is_phys else \"sp_attack\"\n",
    "        d_stat = \"defense\" if is_phys else \"sp_defense\"\n",
    "\n",
    "        p_types = [p_row[\"type1\"], p_row[\"type2\"]]\n",
    "        atk_type = random.choice(p_types)\n",
    "        if atk_type == \"None\":\n",
    "            atk_type = random.choice(Config.TYPE_LIST)\n",
    "            stab = 1.0\n",
    "        else:\n",
    "            stab = 1.5\n",
    "\n",
    "        mult = 1.0\n",
    "        for q_type in [q_row[\"type1\"], q_row[\"type2\"]]:\n",
    "            if q_type != \"None\":\n",
    "                mult *= self.type_matrix.get_multiplier(atk_type, q_type)\n",
    "\n",
    "        attack_power = (stab * mult * (p_row[a_stat] + 1))\n",
    "        defense_power = (q_row[d_stat] + 1)\n",
    "        damage_ratio = attack_power / defense_power\n",
    "        return damage_ratio / (damage_ratio + 1)\n",
    "\n",
    "    def team_vs_team(self, team_F, team_E, df):\n",
    "        score = 0.0\n",
    "        for f in team_F:\n",
    "            for e in team_E:\n",
    "                score += self.duel_prob(df.loc[f], df.loc[e])\n",
    "        return score / 36.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3cbfe769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, df, type_matrix, top_abil, samples):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)  # 确保索引连续\n",
    "        self.type_matrix = type_matrix\n",
    "        self.top_abil = top_abil\n",
    "        self.samples = samples\n",
    "        self.simulator = BattleSimulator(type_matrix)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def get(self, idx):\n",
    "        team_F, team_E = self.samples[idx]\n",
    "        return self._build_graph(team_F, team_E)\n",
    "\n",
    "    def _build_graph(self, team_F, team_E):\n",
    "        # 获取对战双方的宝可梦数据\n",
    "        team_indices = list(team_F) + list(team_E)\n",
    "        rows = self.df.iloc[team_indices]  # 使用iloc避免索引问题\n",
    "        \n",
    "        # 构建节点特征\n",
    "        x = torch.stack([self._row_to_tensor(row) for _, row in rows.iterrows()])\n",
    "\n",
    "        # 构建边连接\n",
    "        edge_index, edge_attr = self._build_edges(rows)\n",
    "        \n",
    "        # 构建图数据\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=torch.tensor([self._calculate_battle_score(team_F, team_E)], dtype=torch.float32)\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def _row_to_tensor(self, row):\n",
    "        \"\"\"将单行数据转换为特征张量\"\"\"\n",
    "        # 标量特征\n",
    "        scalar_features = [\n",
    "            row[\"height_m\"],\n",
    "            row[\"weight_kg\"],\n",
    "            row[\"base_egg_steps\"],\n",
    "            row[\"capture_rate\"],\n",
    "            row[\"experience_growth\"],\n",
    "            row[\"base_happiness\"],\n",
    "            float(row[\"generation\"]),  # 确保为浮点数\n",
    "            float(row[\"is_legendary\"]) # 确保为浮点数\n",
    "        ]\n",
    "        \n",
    "        # 统计值特征\n",
    "        stats_features = [row[stat] for stat in Config.STATS]\n",
    "        \n",
    "        # 类型特征\n",
    "        type_features = [\n",
    "            row[f\"type1_{t}\"] for t in Config.TYPE_LIST\n",
    "        ] + [\n",
    "            row[f\"type2_{t}\"] for t in Config.TYPE_LIST\n",
    "        ]\n",
    "        \n",
    "        # 技能向量\n",
    "        ability_features = row[\"abilities_vec\"].tolist()  # numpy数组转list\n",
    "        \n",
    "        # 合并所有特征\n",
    "        all_features = scalar_features + stats_features + type_features + ability_features\n",
    "        \n",
    "        # 转换为张量\n",
    "        return torch.tensor(all_features, dtype=torch.float32)\n",
    "\n",
    "    def _build_edges(self, rows):\n",
    "        \"\"\"构建全连接边\"\"\"\n",
    "        n = len(rows)\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                \n",
    "                # 获取攻击方和防御方\n",
    "                attacker = rows.iloc[i]\n",
    "                defender = rows.iloc[j]\n",
    "                \n",
    "                # 计算类型克制倍数\n",
    "                type_multiplier = 1.0\n",
    "                for def_type in [defender[\"type1\"], defender[\"type2\"]]:\n",
    "                    if def_type != \"None\":\n",
    "                        type_multiplier *= self.type_matrix.get_multiplier(\n",
    "                            attacker[\"type1\"], \n",
    "                            def_type\n",
    "                        )\n",
    "                \n",
    "                # 计算属性差\n",
    "                stat_diff = attacker[\"attack\"] - defender[\"defense\"]\n",
    "                \n",
    "                edge_index.append([i, j])\n",
    "                edge_attr.append([type_multiplier, stat_diff])\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(edge_index, dtype=torch.long).t().contiguous(),\n",
    "            torch.tensor(edge_attr, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def _calculate_battle_score(self, team_F, team_E):\n",
    "        \"\"\"计算真实对战得分\"\"\"\n",
    "        return self.simulator.team_vs_team(team_F, team_E, self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c62a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# Cell 6: GATRegression模型定义\n",
    "class GATRegression(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden=256, heads=8):\n",
    "        super().__init__()\n",
    "        self.g1 = GATConv(in_channels, hidden, heads=heads, dropout=0.1)\n",
    "        self.g2 = GATConv(hidden*heads, hidden, heads=1, dropout=0.1)\n",
    "        self.lin1 = torch.nn.Linear(hidden, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.elu(self.g1(x, edge_index))\n",
    "        x = F.elu(self.g2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        return self.lin2(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "36c65643",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# Cell 7: Trainer类定义\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model.to(Config.DEVICE)\n",
    "        self.loader = DataLoader(dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "    def train(self, epochs=Config.NUM_EPOCHS):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            loss_cum = 0\n",
    "            for batch in self.loader:\n",
    "                batch = batch.to(Config.DEVICE)\n",
    "                self.optimizer.zero_grad()\n",
    "                pred = self.model(batch)\n",
    "                loss = F.mse_loss(pred, batch.y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss_cum += loss.item() * batch.num_graphs\n",
    "            print(f\"Epoch {epoch:02d}  MSE={loss_cum/len(self.loader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e71e6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# Cell 8: GeneticOptimizer类定义\n",
    "class GeneticOptimizer:\n",
    "    def __init__(self, model, df, type_matrix, top_abil):\n",
    "        self.model = model.to(Config.DEVICE)\n",
    "        self.df = df\n",
    "        self.type_matrix = type_matrix\n",
    "        self.top_abil = top_abil\n",
    "        self.simulator = BattleSimulator(type_matrix)\n",
    "\n",
    "    def optimize(self, enemy_team, pop_size=500, generations=150, mutate_p=0.2):\n",
    "        pool = [p for p in self.df.index if p not in enemy_team]\n",
    "        population = [tuple(random.sample(pool, 6)) for _ in range(pop_size)]\n",
    "\n",
    "        for gen in range(generations):\n",
    "            scored = [(t, self._fitness(t, enemy_team)) for t in population]\n",
    "            scored.sort(key=lambda x: x[1], reverse=True)\n",
    "            best_team, best_fit = scored[0]\n",
    "            print(f\"Gen {gen:03d}  best_fit={best_fit:.4f}\")\n",
    "\n",
    "            elite = [t for t, _ in scored[:pop_size//5]]\n",
    "            population = self._evolve_population(elite, pool, pop_size, mutate_p)\n",
    "\n",
    "        return best_team, best_fit\n",
    "\n",
    "    def _fitness(self, team_F, team_E):\n",
    "        g = PokemonDataset(self.df, self.type_matrix, self.top_abil, \n",
    "                          [(team_F, team_E)]).get(0).to(Config.DEVICE)\n",
    "        with torch.no_grad():\n",
    "            return self.model(g).item()\n",
    "\n",
    "    def _evolve_population(self, elite, pool, pop_size, mutate_p):\n",
    "        new_pop = elite.copy()\n",
    "        while len(new_pop) < pop_size:\n",
    "            p1, p2 = random.sample(elite, 2)\n",
    "            child = self._crossover(p1, p2)\n",
    "            if random.random() < mutate_p:\n",
    "                child = self._mutate(child, pool)\n",
    "            new_pop.append(child)\n",
    "        return new_pop\n",
    "\n",
    "    def _crossover(self, p1, p2):\n",
    "        cut = random.randint(1, 5)\n",
    "        return tuple(list(p1)[:cut] + [x for x in p2 if x not in p1][:6-cut])\n",
    "\n",
    "    def _mutate(self, child, pool):\n",
    "        idx = random.randrange(6)\n",
    "        replacement = random.choice(pool)\n",
    "        while replacement in child:\n",
    "            replacement = random.choice(pool)\n",
    "        return tuple(list(child)[:idx] + [replacement] + list(child)[idx+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8adbc457",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "类型特征必须为int8",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[99], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#%%\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Cell 9: 初始化模块并加载数据\u001B[39;00m\n\u001B[0;32m      3\u001B[0m db_loader \u001B[38;5;241m=\u001B[39m DatabaseLoader()\n\u001B[1;32m----> 4\u001B[0m df, top_abil \u001B[38;5;241m=\u001B[39m \u001B[43mdb_loader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 此时会执行新增的类型验证\u001B[39;00m\n\u001B[0;32m      5\u001B[0m type_matrix \u001B[38;5;241m=\u001B[39m TypeEffectiveness()\n",
      "Cell \u001B[1;32mIn[92], line 14\u001B[0m, in \u001B[0;36mDatabaseLoader.load_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     12\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSELECT * FROM pokemon\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_sql(query, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_preprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtop_abil\n",
      "Cell \u001B[1;32mIn[92], line 31\u001B[0m, in \u001B[0;36mDatabaseLoader._preprocess_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_numeric()\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# 最终验证\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_final_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[92], line 97\u001B[0m, in \u001B[0;36mDatabaseLoader._final_validation\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;66;03m# 验证类型特征\u001B[39;00m\n\u001B[0;32m     96\u001B[0m type_cols \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype1_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m Config\u001B[38;5;241m.\u001B[39mTYPE_LIST] \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype2_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m Config\u001B[38;5;241m.\u001B[39mTYPE_LIST]\n\u001B[1;32m---> 97\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf[col]\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mint8 \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m type_cols), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m类型特征必须为int8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# 验证数值列\u001B[39;00m\n\u001B[0;32m    100\u001B[0m numeric_cols \u001B[38;5;241m=\u001B[39m Config\u001B[38;5;241m.\u001B[39mSTATS \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_legendary\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mAssertionError\u001B[0m: 类型特征必须为int8"
     ]
    }
   ],
   "source": [
    "##%%\n",
    "# Cell 9: 初始化模块并加载数据\n",
    "db_loader = DatabaseLoader()\n",
    "df, top_abil = db_loader.load_data()  # 此时会执行新增的类型验证\n",
    "type_matrix = TypeEffectiveness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: 生成训练数据\n",
    "samples = [\n",
    "    (tuple(random.sample(df.index.tolist(), 6)),\n",
    "     tuple(random.sample(df.index.tolist(), 6)))\n",
    "    for _ in range(Config.NUM_RANDOM_TEAMS)\n",
    "]\n",
    "dataset = PokemonDataset(df, type_matrix, top_abil, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4389b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 验证失败：can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool. ===\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 3\u001B[0m, in \u001B[0;36multimate_validation\u001B[1;34m(dataset)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m----> 3\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=== 验证通过 ===\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[48], line 17\u001B[0m, in \u001B[0;36mPokemonDataset.get\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     16\u001B[0m team_F, team_E \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[idx]\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mteam_F\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteam_E\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[48], line 21\u001B[0m, in \u001B[0;36mPokemonDataset._build_graph\u001B[1;34m(self, team_F, team_E)\u001B[0m\n\u001B[0;32m     20\u001B[0m rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;28mlist\u001B[39m(team_F)\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlist\u001B[39m(team_E)]\n\u001B[1;32m---> 21\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_row_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _, r \u001B[38;5;129;01min\u001B[39;00m rows\u001B[38;5;241m.\u001B[39miterrows()])\n\u001B[0;32m     23\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m12\u001B[39m\n",
      "Cell \u001B[1;32mIn[48], line 50\u001B[0m, in \u001B[0;36mPokemonDataset._row_to_tensor\u001B[1;34m(self, row)\u001B[0m\n\u001B[0;32m     44\u001B[0m scalar \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\n\u001B[0;32m     45\u001B[0m     row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheight_m\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_kg\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_egg_steps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     46\u001B[0m     row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapture_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperience_growth\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     47\u001B[0m     row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_happiness\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_legendary\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     48\u001B[0m ], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m---> 50\u001B[0m stats \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43mConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSTATS\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m types \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(row[[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m) \n\u001B[0;32m     52\u001B[0m                         \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m Config\u001B[38;5;241m.\u001B[39mTYPE_LIST]]\u001B[38;5;241m.\u001B[39mvalues, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mIndexingError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# 执行验证\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m \u001B[43multimate_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[56], line 9\u001B[0m, in \u001B[0;36multimate_validation\u001B[1;34m(dataset)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=== 验证失败：\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ===\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 逐层诊断\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m rows \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, row \u001B[38;5;129;01min\u001B[39;00m rows\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32md:\\python\\.conda\\envs\\chemist\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_value(\u001B[38;5;241m*\u001B[39mkey, takeable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_takeable)\n\u001B[1;32m-> 1184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1186\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m     axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32md:\\python\\.conda\\envs\\chemist\\Lib\\site-packages\\pandas\\core\\indexing.py:1371\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_tuple\u001B[1;34m(self, tup)\u001B[0m\n\u001B[0;32m   1368\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_lowerdim(tup)\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;66;03m# no multi-index, so validate all of the indexers\u001B[39;00m\n\u001B[1;32m-> 1371\u001B[0m tup \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_tuple_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;66;03m# ugly hack for GH #836\u001B[39;00m\n\u001B[0;32m   1374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_multi_take_opportunity(tup):\n",
      "File \u001B[1;32md:\\python\\.conda\\envs\\chemist\\Lib\\site-packages\\pandas\\core\\indexing.py:962\u001B[0m, in \u001B[0;36m_LocationIndexer._validate_tuple_indexer\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    957\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m    958\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_tuple_indexer\u001B[39m(\u001B[38;5;28mself\u001B[39m, key: \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m:\n\u001B[0;32m    959\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    960\u001B[0m \u001B[38;5;124;03m    Check the key for valid keys across my indexer.\u001B[39;00m\n\u001B[0;32m    961\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 962\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_key_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    963\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_ellipsis(key)\n\u001B[0;32m    964\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(key):\n",
      "File \u001B[1;32md:\\python\\.conda\\envs\\chemist\\Lib\\site-packages\\pandas\\core\\indexing.py:1001\u001B[0m, in \u001B[0;36m_LocationIndexer._validate_key_length\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    999\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m IndexingError(_one_ellipsis_message)\n\u001B[0;32m   1000\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key_length(key)\n\u001B[1;32m-> 1001\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m IndexingError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mToo many indexers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1002\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m key\n",
      "\u001B[1;31mIndexingError\u001B[0m: Too many indexers"
     ]
    }
   ],
   "source": [
    "def ultimate_validation(dataset):\n",
    "    try:\n",
    "        sample = dataset.get(0)\n",
    "        print(\"=== 验证通过 ===\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"=== 验证失败：{str(e)} ===\")\n",
    "        # 逐层诊断\n",
    "        rows = dataset.df.loc[dataset.samples[0][0] + dataset.samples[0][1]]\n",
    "        for idx, row in rows.iterrows():\n",
    "            try:\n",
    "                tensor = dataset._row_to_tensor(row)\n",
    "                print(f\"行 {idx} 转换成功\")\n",
    "            except Exception as ve:\n",
    "                print(f\"行 {idx} 转换失败：{str(ve)}\")\n",
    "                print(\"问题数据详情：\")\n",
    "                print(\"能力向量:\", type(row[\"abilities_vec\"]), row[\"abilities_vec\"].dtype)\n",
    "                print(\"类型特征:\", row[[f\"type1_{t}\" for t in Config.TYPE_LIST[:3]]])\n",
    "        return False\n",
    "\n",
    "# 执行验证\n",
    "ultimate_validation(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18891d0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m向量类型示例:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mtype\u001B[39m(df\u001B[38;5;241m.\u001B[39mabilities_vec\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]))  \u001B[38;5;66;03m# 应显示numpy.ndarray\u001B[39;00m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m元素类型示例:\u001B[39m\u001B[38;5;124m\"\u001B[39m, df\u001B[38;5;241m.\u001B[39mabilities_vec\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype)  \u001B[38;5;66;03m# 应显示float32\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[43mvalidate_tensor_construction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[54], line 2\u001B[0m, in \u001B[0;36mvalidate_tensor_construction\u001B[1;34m(dataset)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvalidate_tensor_construction\u001B[39m(dataset):\n\u001B[1;32m----> 2\u001B[0m     sample_data \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m=== 节点特征验证 ===\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m特征张量类型:\u001B[39m\u001B[38;5;124m\"\u001B[39m, sample_data\u001B[38;5;241m.\u001B[39mx\u001B[38;5;241m.\u001B[39mdtype)  \u001B[38;5;66;03m# 应显示torch.float32\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[48], line 17\u001B[0m, in \u001B[0;36mPokemonDataset.get\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     16\u001B[0m     team_F, team_E \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[idx]\n\u001B[1;32m---> 17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mteam_F\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteam_E\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[48], line 21\u001B[0m, in \u001B[0;36mPokemonDataset._build_graph\u001B[1;34m(self, team_F, team_E)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_graph\u001B[39m(\u001B[38;5;28mself\u001B[39m, team_F, team_E):\n\u001B[0;32m     20\u001B[0m     rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;28mlist\u001B[39m(team_F)\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlist\u001B[39m(team_E)]\n\u001B[1;32m---> 21\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_row_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _, r \u001B[38;5;129;01min\u001B[39;00m rows\u001B[38;5;241m.\u001B[39miterrows()])\n\u001B[0;32m     23\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m12\u001B[39m\n\u001B[0;32m     24\u001B[0m     send, recv, edge_attr \u001B[38;5;241m=\u001B[39m [], [], []\n",
      "Cell \u001B[1;32mIn[48], line 50\u001B[0m, in \u001B[0;36mPokemonDataset._row_to_tensor\u001B[1;34m(self, row)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_row_to_tensor\u001B[39m(\u001B[38;5;28mself\u001B[39m, row):\n\u001B[0;32m     44\u001B[0m     scalar \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\n\u001B[0;32m     45\u001B[0m         row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheight_m\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_kg\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_egg_steps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     46\u001B[0m         row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapture_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperience_growth\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     47\u001B[0m         row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_happiness\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_legendary\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     48\u001B[0m     ], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m---> 50\u001B[0m     stats \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43mConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSTATS\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     types \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(row[[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m) \n\u001B[0;32m     52\u001B[0m                             \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m Config\u001B[38;5;241m.\u001B[39mTYPE_LIST]]\u001B[38;5;241m.\u001B[39mvalues, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     53\u001B[0m     abil \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabilities_vec\u001B[39m\u001B[38;5;124m\"\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "def validate_tensor_construction(dataset):\n",
    "    sample_data = dataset.get(0)\n",
    "    \n",
    "    print(\"\\n=== 节点特征验证 ===\")\n",
    "    print(\"特征张量类型:\", sample_data.x.dtype)  # 应显示torch.float32\n",
    "    print(\"特征形状:\", sample_data.x.shape)     # 应为(12, 特征维度)\n",
    "    \n",
    "    print(\"\\n=== 边特征验证 ===\")\n",
    "    print(\"边属性类型:\", sample_data.edge_attr.dtype)  # 应显示torch.float32\n",
    "    \n",
    "    print(\"\\n=== 类型特征采样验证 ===\")\n",
    "    type_cols = [f\"type1_{t}\" for t in Config.TYPE_LIST[:3]]\n",
    "    print(df[type_cols].head(3).values)  # 应显示0/1的整数\n",
    "    \n",
    "    print(\"\\n=== 能力向量验证 ===\")\n",
    "    print(\"向量类型示例:\", type(df.abilities_vec.iloc[0]))  # 应显示numpy.ndarray\n",
    "    print(\"元素类型示例:\", df.abilities_vec.iloc[0].dtype)  # 应显示float32\n",
    "\n",
    "validate_tensor_construction(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cabd9dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#%%\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# Cell 11: 初始化并训练模型\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m GATRegression(\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnum_node_features)\n\u001B[0;32m      4\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(model, dataset)\n\u001B[0;32m      5\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "Cell \u001B[1;32mIn[34], line 17\u001B[0m, in \u001B[0;36mPokemonDataset.get\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     16\u001B[0m     team_F, team_E \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[idx]\n\u001B[1;32m---> 17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mteam_F\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteam_E\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[34], line 21\u001B[0m, in \u001B[0;36mPokemonDataset._build_graph\u001B[1;34m(self, team_F, team_E)\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_graph\u001B[39m(\u001B[38;5;28mself\u001B[39m, team_F, team_E):\n\u001B[0;32m     20\u001B[0m     rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;28mlist\u001B[39m(team_F)\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlist\u001B[39m(team_E)]\n\u001B[1;32m---> 21\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack([\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_row_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _, r \u001B[38;5;129;01min\u001B[39;00m rows\u001B[38;5;241m.\u001B[39miterrows()])\n\u001B[0;32m     23\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m12\u001B[39m\n\u001B[0;32m     24\u001B[0m     send, recv, edge_attr \u001B[38;5;241m=\u001B[39m [], [], []\n",
      "Cell \u001B[1;32mIn[34], line 50\u001B[0m, in \u001B[0;36mPokemonDataset._row_to_tensor\u001B[1;34m(self, row)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_row_to_tensor\u001B[39m(\u001B[38;5;28mself\u001B[39m, row):\n\u001B[0;32m     44\u001B[0m     scalar \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\n\u001B[0;32m     45\u001B[0m         row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheight_m\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_kg\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_egg_steps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     46\u001B[0m         row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapture_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperience_growth\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     47\u001B[0m         row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbase_happiness\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_legendary\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     48\u001B[0m     ], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m---> 50\u001B[0m     stats \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43mConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSTATS\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     types \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(row[[\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m) \n\u001B[0;32m     52\u001B[0m                             \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m Config\u001B[38;5;241m.\u001B[39mTYPE_LIST]]\u001B[38;5;241m.\u001B[39mvalues, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     53\u001B[0m     abil \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabilities_vec\u001B[39m\u001B[38;5;124m\"\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "##%%\n",
    "# Cell 11: 初始化并训练模型\n",
    "model = GATRegression(dataset.get(0).num_node_features)\n",
    "trainer = Trainer(model, dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb55dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# Cell 12: 运行遗传算法优化\n",
    "enemy_team = df[df.name.isin([\"Pikachu\",\"Charizard\"])].index.tolist()[:6]\n",
    "optimizer = GeneticOptimizer(model, df, type_matrix, top_abil)\n",
    "best_team, score = optimizer.optimize(tuple(enemy_team))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%\n",
    "# Cell 13: 输出最终结果\n",
    "print(\"\\n=== 推荐克制队伍 ===\")\n",
    "print(df.loc[list(best_team), \"name\"].tolist())\n",
    "print(f\"预测胜率: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
